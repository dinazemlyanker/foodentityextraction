{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8929eb9",
   "metadata": {},
   "source": [
    "# NER Summary - Data Culture Group\n",
    "This document should serve as a summary of the work completed from May 16th, 2022 to September 28th, 2022. Along with it are a variety of resources regarding use of spaCy, Prodigy, and other implements that support the work completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe510449",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f3719",
   "metadata": {},
   "source": [
    "## I. Testing and Training Datasets\n",
    "As of October 12th, 2022, we have a total of **3,790** annotations for training data, **780** annotations for testing data, and **624** \"recall\" annotations.\n",
    "\n",
    "The corpus utilizes text sourced from exclusively Bon Appetit's articles, Instagram Posts, and Youtube transcripts.\n",
    "\n",
    "Training datasets (training.spacy) were generated using the Prodigy annotation tool over a randomized stream of documents from the corpus. More often than not, suggestions for annotated data were generated by the model in development, and then either kept or corrected. Annotated text has n-gram spans which indicate proper food entities in a sentence. Annotations are labelled \"FOOD\".\n",
    "\n",
    "The evaluation dataset (eval-data.spacy) was generated using the same method as the training datasets.\n",
    "\n",
    "The \"recall\" annotations dataset (recall-data.spacy) was generated in order to improve the model's ability to make guesses about rare or non-English food names. Articles were hand-selected from the Bon Appetit corpus which reflected food entities from cuisines the model struggled to parse. These articles then entered the same Prodigy annotation pipeline as the above four datasets.\n",
    "\n",
    "In Prodigy, data is managed through SQL databases. The database takes as its default input and output a JSON Lines file (**.jsonl**).\n",
    "\n",
    "## II. spaCy\n",
    "### spaCy Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772b68fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[38;5;1m✘ The provided output file already exists. To force overwriting the\r\n",
      "config file, set the --force or -F flag.\u001b[0m\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!spacy init config -p parser,ner base_config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e526e2",
   "metadata": {},
   "source": [
    "This command will create the default config file for the model. You do not need this step per se; I will attach two additional config files that follow most of the same parameters as the one above.\n",
    "\n",
    "File one -- \"base_config.cfg\" -- uses a tok2vec along with the default spacy pipeline (parser, ner). The tok2vec layer provides word embeddings to incorporate within the named entity recognition process, and the NER is configured to listen to the tok2vec layer when it makes decisions. This configuration for the model does not require that many resources to run, but does not include the BERT transformers that Professor Bhargava has requested.\n",
    "\n",
    "File two -- \"trf_config.cfg\" -- uses a transformer layer along with the default spacy pipeline. We'll talk more about the use of transformers and BERT on this project later. The transformer and tok2vec pipes are *mutually exclusive*, meaning that a transformer layer replaces the traditional vector embedding approach in tok2vec. This is expected to improve the model's overall performance and make successful long-range guesses, but requires a GPU in order to run properly, which Northeastern provides through Discovery. This transformer model is the **roBERTa-base model**, for which you can find documentation here: https://huggingface.co/roberta-base. \n",
    "\n",
    "### spaCy Model Creation\n",
    "The spaCy library has a train command in the CLI, which uses the config files from above. See the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26a5e56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: food_entity_recognizer\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: food_entity_recognizer\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-10-14 15:37:57,924] [INFO] Set up nlp object from config\n",
      "[2022-10-14 15:37:57,936] [INFO] Pipeline: ['tok2vec', 'parser', 'ner']\n",
      "[2022-10-14 15:37:57,941] [INFO] Created vocabulary\n",
      "[2022-10-14 15:37:57,941] [INFO] Finished initializing nlp object\n",
      "[2022-10-14 15:38:08,855] [INFO] Initialized pipeline components: ['tok2vec', 'parser', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'parser', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS PARSER  LOSS NER  DEP_UAS  DEP_LAS  SENTS_F  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  -----------  --------  -------  -------  -------  ------  ------  ------  ------\n",
      "  0       0          0.00         0.00     40.91     0.00     0.00   100.00    0.00    0.00    0.00    0.00\n",
      "  0     200         26.02         0.00   1869.14     0.00     0.00   100.00    0.00    0.00    0.00    0.00\n",
      "  0     400         35.04         0.00   1492.77     0.00     0.00   100.00    7.97   53.75    4.30    0.04\n",
      "  0     600         44.84         0.00   1780.09     0.00     0.00   100.00   51.03   53.90   48.45    0.26\n",
      "  1     800        427.81         0.00   1877.41     0.00     0.00   100.00   33.01   73.07   21.32    0.17\n",
      "  1    1000         95.88         0.00   2045.46     0.00     0.00   100.00   23.97   77.96   14.16    0.12\n",
      "  1    1200        112.83         0.00   2290.07     0.00     0.00   100.00   55.71   60.67   51.50    0.28\n",
      "  2    1400        136.44         0.00   2500.61     0.00     0.00   100.00   47.16   75.30   34.33    0.24\n",
      "  3    1600        116.27         0.00   2675.53     0.00     0.00   100.00   57.04   65.86   50.30    0.29\n",
      "  3    1800       1031.81         0.00   3309.75     0.00     0.00   100.00   55.71   71.10   45.80    0.28\n",
      "  4    2000        412.47         0.00   3352.73     0.00     0.00   100.00   57.58   73.69   47.25    0.29\n",
      "  5    2200        902.60         0.00   3577.23     0.00     0.00   100.00   57.81   75.59   46.80    0.29\n",
      "  7    2400       3355.59         0.00   3893.82     0.00     0.00   100.00   57.29   77.77   45.35    0.29\n",
      "  8    2600        548.20         0.00   4278.35     0.00     0.00   100.00   60.37   70.55   52.75    0.30\n",
      "  9    2800       4071.34         0.00   4274.25     0.00     0.00   100.00   60.47   72.93   51.65    0.30\n",
      " 11    3000        794.25         0.00   4344.98     0.00     0.00   100.00   59.83   71.86   51.25    0.30\n",
      " 12    3200        543.22         0.00   4245.84     0.00     0.00   100.00   61.28   73.09   52.75    0.31\n",
      " 14    3400        518.83         0.00   4082.14     0.00     0.00   100.00   58.41   79.25   46.25    0.29\n",
      " 15    3600       1260.33         0.00   4032.18     0.00     0.00   100.00   60.60   74.33   51.15    0.30\n",
      " 17    3800       3921.53         0.00   4271.78     0.00     0.00   100.00   61.61   74.15   52.70    0.31\n",
      " 18    4000        938.70         0.00   4102.49     0.00     0.00   100.00   59.28   77.74   47.90    0.30\n",
      " 19    4200       6275.69         0.00   3851.07     0.00     0.00   100.00   60.80   75.26   51.00    0.30\n",
      " 21    4400        851.06         0.00   3804.72     0.00     0.00   100.00   58.97   77.61   47.55    0.29\n",
      " 22    4600      20229.91         0.00   3975.41     0.00     0.00   100.00   52.93   88.90   37.69    0.26\n",
      " 24    4800       1842.24         0.00   3862.79     0.00     0.00   100.00   60.80   77.56   50.00    0.30\n",
      " 25    5000      23661.13         0.00   3898.12     0.00     0.00   100.00   54.43   84.51   40.14    0.27\n",
      " 27    5200        750.77         0.00   3843.28     0.00     0.00   100.00   61.59   73.49   53.00    0.31\n",
      " 28    5400       1581.36         0.00   3768.77     0.00     0.00   100.00   59.04   78.26   47.40    0.30\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "food_entity_recognizer/model-last\n"
     ]
    }
   ],
   "source": [
    "!spacy train base_config.cfg --paths.train ./training.spacy --paths.dev ./eval-data.spacy -o food_entity_recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ddb5e",
   "metadata": {},
   "source": [
    "Do note that the pipeline will save *two* models: the **best** performance, which I believe is evaluated according to the \"score\" on the far right, and the **last** performance, which is the last iteration of the model before saving. These are saved to ./model-best and ./model-last, respectively.\n",
    "### spaCy Model Evaluation\n",
    "\n",
    "spaCy offers users a basic command for evaluation. \"spacy evaluate\" takes the config path and the path to evaluation data in spacy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8584a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK      100.00\n",
      "UAS      -     \n",
      "LAS      -     \n",
      "NER P    61.34 \n",
      "NER R    30.29 \n",
      "NER F    40.56 \n",
      "SENT P   -     \n",
      "SENT R   -     \n",
      "SENT F   -     \n",
      "SPEED    17249 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "           P       R       F\n",
      "FOOD   61.34   30.29   40.56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!spacy evaluate ./food_entity_recognizer/model-last ./eval-data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b2259",
   "metadata": {},
   "source": [
    "The model, clearly, is not doing amazing. I'll talk about why this could be towards the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9f907",
   "metadata": {},
   "source": [
    "## III. Prodigy\n",
    "\n",
    "### Initialization:\n",
    "\n",
    "Prodigy is a premium software, and as such a software key is needed to install it. The command below has the software key that belongs to Mediacloud.\n",
    "Do note that this key has a limited number of downloads for each released Prodigy version. I don't believe executing the command below counts as a \"download\" under this limit, this is useful to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prodigy -f https://E9D3-7A82-009E-D41C@download.prodi.gy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ad056",
   "metadata": {},
   "source": [
    "### Prodigy Model Creation\n",
    "\n",
    "Prodigy does not necessarily require a config file in order to function. You can include a config file using -c. \n",
    "In order to train the model in Prodigy, you need to use the JSONL version of the datasets, which is also included. These JSONL datasets are to be plugged into SQL, so they need to be both downloaded and imported into the Prodigy SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcacabb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prodigy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprodigy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connect\n\u001b[1;32m      2\u001b[0m db \u001b[38;5;241m=\u001b[39m connect()\n\u001b[1;32m      3\u001b[0m all_dataset_names \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mdatasets\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prodigy'"
     ]
    }
   ],
   "source": [
    "!prodigy db-in training training.jsonl\n",
    "!prodigy db-in recall-data recall-data.jsonl\n",
    "!prodigy db-in eval-data eval-data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce624b8a",
   "metadata": {},
   "source": [
    "Once datasets have been imported, you can use the following command to generate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dacabc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: prodigy\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy train -n training,recall-data food_entity_recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f984234",
   "metadata": {},
   "source": [
    "Do note that Prodigy does *not* make use of evaluation data, but rather just partitions off 20% of the training data for evaluation. If you want, you can use the evaluation dataset to aid in training, but there is little reason to do so.\n",
    "### Annotation using Prodigy\n",
    "\n",
    "Prodigy mainly serves as an annotation tool to supplement those using spaCy models. Here is how to use Prodigy to generate more annotations to work with.\n",
    "\n",
    "First, a source document is needed as a stream. I have been working with the file dubbed \"compiled_jsons.json\", which contains un-annotated text sourced from Youtube video transcripts, website articles, and Instagram captions from Bon Appetit that has been shuffled. Somewhat barbarically, I manually updated this document, which means once a cycle of annotations had been done, I went into the document and removed those text sources by hand. They are placed in a different file -- \"archived_jsons.json\".\n",
    "\n",
    "Second, for certain types of annotation methods, a pre-existing model must exist to make initial guesses at food entities to correct. This is not universally required, but can hasten the process of data collection if so desired\n",
    "\n",
    "Finally, a dataset *within* Prodigy's SQL database is necessary. If it does not already exist, Prodigy will make the dataset with the requested name, but do be sure to collect these annotations from the SQL database if they are intended for use with spaCy training or annotation.\n",
    "\n",
    "#### Method One: ner.manual\n",
    "\n",
    "No model required! This annotation command will provide you **raw text** to annotate, *without* help from a model.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9092a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!prodigy ner.manual new_annotations ./compiled_jsons.json -l=\"FOOD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d8cf8",
   "metadata": {},
   "source": [
    "#### Method Two: ner.correct\n",
    "\n",
    "This annotation command provides you the model's **best guess** at annotation sin the document. Your job is to correct these annotations, which provides perfected data. Depending on the quality of the model used, this can significantly hasten the time spent working with data. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc095a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: prodigy\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy ner.correct new_annotations ./food_entity_recognizer/model-best ./compiled_jsons.json -l=\"FOOD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e32716",
   "metadata": {},
   "source": [
    "#### Final note: .jsonl to .spacy conversion:\n",
    "\n",
    "I recommend that data be kepy in .jsonl format, as .spacy carries less metadata and annotation information because it only retains the annotations. Here is a function that converts jsonl data to spacy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f4cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "def jsonl_spacy(filename):\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    with open(filename + \".jsonl\", 'r') as fl:\n",
    "        take = fl.readlines()\n",
    "    doc_bin = DocBin()\n",
    "    for thing in take:\n",
    "        lnput = json.loads(thing)\n",
    "        text = lnput['text']\n",
    "        spans = [(s['start'], s['end'], 'FOOD') for s in lnput['spans']]\n",
    "        example = Example.from_dict(nlp(text), dict(text= text, entities=spans))\n",
    "        doc_bin.add(example.reference)\n",
    "    doc_bin.to_disk(filename + \".spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10116bfb",
   "metadata": {},
   "source": [
    "## IV. BERT and Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d2d71",
   "metadata": {},
   "source": [
    "We implemented BERT and BERT-like transformer pipes as components preceding named entity recognition. BERT (Bidirectional Encoder Representations from Transformers) use two non-directional objectives in order to train a model to assign vector representations to each token. BERT also uses a unique tokenizer, that segments words into wordpieces  to offer more precise guesses on the nature of certain tokens. These strings can be re-patched together under the classification layer that takes the Transformer output for the NER. In order to use the BERT model, you can initialize through the spacy config provided (\"trf_config.cfg\"), so long as you ensure that a GPU is available to use.\n",
    "#### Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4045a33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy train [OPTIONS] CONFIG_PATH\r\n",
      "Try 'python -m spacy train --help' for help.\r\n",
      "\r\n",
      "Error: Invalid value for 'CONFIG_PATH': Path './trf_config.cfg' does not exist.\r\n"
     ]
    }
   ],
   "source": [
    "!spacy train -o bert_entity_recognizer -g 0 trf-config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8148ec7",
   "metadata": {},
   "source": [
    "#### Using Prodigy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f81bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: prodigy\r\n"
     ]
    }
   ],
   "source": [
    "!prodigy train -c trf_config.cfg -n training,recall-data -g 0 bert_entity_recognizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
