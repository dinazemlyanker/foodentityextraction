{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e6a46a",
   "metadata": {},
   "source": [
    "# Model Tester (v1.1)\n",
    "Run the code below only once. It might take a few minutes, let it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ad4960-0d8e-4c17-928f-b33237d331d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_lg')\r\n"
     ]
    }
   ],
   "source": [
    "# Import libraries:\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy wget -q\n",
    "!{sys.executable} -m spacy download en_core_web_lg -q\n",
    "import os\n",
    "import pickle\n",
    "import spacy\n",
    "from thinc.api import Config\n",
    "from spacy import Language\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_lg\n",
    "import wget\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "# Build the model. We only do this once per Binder instance.\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "url = \"https://mediacloud-ihop.s3.amazonaws.com/models/spacy_model.p\"\n",
    "take1 = wget.download(url)\n",
    "with open(\"spacy_model.p\", \"rb\") as h:\n",
    "\ttake = pickle.load(h)\n",
    "config = Config().from_disk(\"./config.cfg\")\n",
    "lang_cls = spacy.util.get_lang_class(config[\"nlp\"][\"lang\"])\n",
    "nlp = lang_cls.from_config(config)\n",
    "nlp = nlp.from_bytes(take)\n",
    "# The model should now be a file named \"spacy_model.p\" in the nav pane. This will NOT be in the Github.\n",
    "\n",
    "\n",
    "##Here are some functions for bigger testing.\n",
    "\n",
    "#This gives precision and recall numbers for a given dataframe created above.\n",
    "def precall(data):\n",
    "\tfalse_positives = 0\n",
    "\tfalse_negatives = 0\n",
    "\ttrue_positives = 0\n",
    "\tfor x in range(len(data)):\n",
    "\t\texpected = data.iloc[x,1]\n",
    "\t\tactual = data.iloc[x,2]\n",
    "\t\tif math.isnan(expected - actual): continue\n",
    "\t\telse:\n",
    "\t\t\tif expected == actual:\n",
    "\t\t\t\ttrue_positives += actual\n",
    "\t\t\telif expected > actual:\n",
    "\t\t\t\ttrue_positives += actual\n",
    "\t\t\t\tfalse_negatives += (expected - actual)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttrue_positives += expected\n",
    "\t\t\t\tfalse_positives += (actual - expected)\n",
    "\tprecision = true_positives / (true_positives + false_positives)\n",
    "\trecall = true_positives / (true_positives + false_negatives)\n",
    "\tprint(\"PRECISION: \" + str(precision))\n",
    "\tprint(\"RECALL: \" + str(recall))\n",
    "\n",
    "#This function takes the storyid for a storyjson blog post, and returns a dataframe with expected and actual results for each term in the post.\n",
    "def build_food_tester(convert):\n",
    "\n",
    "\t#First, do the csv results.\n",
    "\tjsons_export = dict()\n",
    "\tfilepath = \"./storyjsons/\" + convert + \".json\"\n",
    "\twith open(filepath, 'rb') as json_file:\n",
    "\t\tfoo = json.load(json_file)\n",
    "\t\tbar = foo['content']\n",
    "\t\tdoc = nlp(bar) #Don't worry about any of these :)\n",
    "\n",
    "\t\tfor ents in doc.ents:\n",
    "\t\t\tif(ents.label_ != \"FOOD\"): continue\n",
    "\t\t\telif jsons_export.get(ents.text, -1) != -1:\n",
    "\t\t\t\tjsons_export[ents.text] += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tjsons_export[ents.text] = 1\n",
    "\t\n",
    "\t#Next, collect the data from the Manual Tests\n",
    "\tfilepath = \"./csvs/\" + convert + \".csv\"\n",
    "\tcsvs_export = pd.read_csv(filepath)\n",
    "\tcsvs_export = dict(zip(csvs_export.iloc[:,0], csvs_export.iloc[:,1]))\n",
    "\t#print(csvs_export)\n",
    "\n",
    "\t#Finally, put the lists together.\n",
    "\tdf = pd.DataFrame()\n",
    "\tdf = df.reindex(columns = [\"term\", \"expected\", \"actual\"])\n",
    "\tfor key in csvs_export:\n",
    "\t\tvalue3 = 0\n",
    "\t\tif jsons_export.get(key, -1) != -1:\n",
    "\t\t\tvalue3 = jsons_export[key]\n",
    "\t\t\tjsons_export[key] = -2\n",
    "\t\tdf.loc[len(df.index)] = [key, csvs_export[key], value3]\n",
    "\n",
    "\tfor key in jsons_export:\n",
    "\t\tif jsons_export[key] != -2:\n",
    "\t\t\tdf.loc[len(df.index)] = [key, 0, jsons_export[key]]\n",
    "\tdf = df.sort_values('term')\n",
    "\treturn df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a62b31",
   "metadata": {},
   "source": [
    "### User-Input Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962d611-3103-4ff7-8611-163f8a56127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a set of code for you to test everything out on your own; a personal sandbox!\n",
    "doc = nlp(\"bacon egg and cheese sandwich\")\n",
    "for token in doc:\n",
    "\tprint(token.text, token.pos_)\n",
    "for chunk in doc.noun_chunks:\n",
    "\tprint(chunk.text, chunk.root.text)\n",
    "for ents in doc.ents:\n",
    "\tprint(ents.text, ents.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adee444-e884-4c59-85b2-f9f7e07c478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer tags:\n",
      "[]\n",
      "Correct answer:\n",
      "[]\n",
      "Computer tags:\n",
      "['50%']\n",
      "Correct answer:\n",
      "[]\n",
      "Computer tags:\n",
      "['bacon', 'cheeseburger', 'onion', 'tomato', 'salsa', 'lemon', 'juice']\n",
      "Correct answer:\n",
      "['bacon', 'cheeseburger', 'lettuce', 'onion', 'tomato', 'salsa', 'lemon juice']\n",
      "Computer tags:\n",
      "['pepper', 'seasoning']\n",
      "Correct answer:\n",
      "['red pepper flakes', 'seasoning']\n",
      "Computer tags:\n",
      "['egg', 'eggs']\n",
      "Correct answer:\n",
      "['egg', 'egg', 'millefeuille']\n"
     ]
    }
   ],
   "source": [
    "# Testing random sentences.\n",
    "testsentences = ['', \n",
    "                 'get your car insurance at 50% average rates today by calling 334-808-1992', \n",
    "                 'today i ate a bacon cheeseburger with lettuce, onion and tomato. the salsa added to the top was too runny, so i would add some lemon juice on top.', \n",
    "                 'red pepper flakes are a great seasoning to add to many dishes.', \n",
    "                 'just one egg is fine, but i think two eggs will help the millefeuille maintain structure'\n",
    "                ]\n",
    "testanswers = [[], \n",
    "               [], \n",
    "               ['bacon', 'cheeseburger', 'lettuce', 'onion', 'tomato', 'salsa', 'lemon juice'], \n",
    "               ['red pepper flakes', 'seasoning'], \n",
    "               ['egg', 'egg', 'millefeuille']\n",
    "              ]\n",
    "counter = 0\n",
    "for sentence in testsentences:\n",
    "    doc = nlp(sentence)\n",
    "    nlp_answers = []\n",
    "    print(\"Computer tags:\")\n",
    "    for ents in doc.ents:\n",
    "        nlp_answers.append(ents.text)\n",
    "    print(nlp_answers)\n",
    "    print(\"Correct answer:\")\n",
    "    print(testanswers[counter])\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cd571",
   "metadata": {},
   "source": [
    "### Manual Tests (from manually-entered csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1486bc86-c0a3-4d7a-a609-07c10501407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ff401e9686de3bec35052aa33a8382c5\n",
      "\n",
      "                        term  expected  actual\n",
      "27                     azuki       1.0     0.0\n",
      "37                     broth       1.0     1.0\n",
      "51                      cake       0.0     1.0\n",
      "29         candied chestnuts       1.0     0.0\n",
      "40                      chew       0.0     2.0\n",
      "42                     chewy       0.0     2.0\n",
      "28              chiffon cake       1.0     0.0\n",
      "56                     chips       0.0     1.0\n",
      "55                 chocolate       0.0     2.0\n",
      "38  chocolate chip ice cream       1.0     0.0\n",
      "39           chocolate chips       1.0     0.0\n",
      "45                confection       0.0     1.0\n",
      "26                cornflakes       1.0     0.0\n",
      "44                     cream       0.0     3.0\n",
      "4                      dango       9.0     0.0\n",
      "34                     dashi       1.0     0.0\n",
      "52                   dessert       0.0     2.0\n",
      "0                  dumplings       3.0     2.0\n",
      "36                       egg       1.0     1.0\n",
      "7                      flour       NaN     4.0\n",
      "47                     glaze       0.0     4.0\n",
      "43                       ice       0.0     4.0\n",
      "8                  ice cream       3.0     0.0\n",
      "15                     maple       1.0     0.0\n",
      "30               maple glaze       1.0     0.0\n",
      "18               maple syrup       3.0     0.0\n",
      "53                      miso       0.0     1.0\n",
      "17           mitarashi dango       2.0     0.0\n",
      "1                      mochi       6.0     0.0\n",
      "13                   mochiko       1.0     0.0\n",
      "33                     onion       1.0     1.0\n",
      "31                     ozoni       3.0     0.0\n",
      "24                  parfaits       2.0     0.0\n",
      "50                    peanut       0.0     1.0\n",
      "23             peanut powder       1.0     0.0\n",
      "54                     poach       0.0     1.0\n",
      "21             potato starch       1.0     0.0\n",
      "35                  red miso       1.0     0.0\n",
      "41                      rice       0.0     5.0\n",
      "5                 rice flour       3.0     0.0\n",
      "6             rice mochigome       NaN     0.0\n",
      "48                     sauce       0.0     2.0\n",
      "11               shiratamako       2.0     0.0\n",
      "12               silken tofu       1.0     0.0\n",
      "46                    smooth       0.0     1.0\n",
      "25                soft-serve       1.0     0.0\n",
      "10                      soup       4.0     3.0\n",
      "16                       soy       2.0     0.0\n",
      "19                 soy sauce       2.0     0.0\n",
      "32               sticky rice       1.0     0.0\n",
      "49                     sugar       0.0     2.0\n",
      "9                      syrup       NaN     5.0\n",
      "22     toasted soybean powde       1.0     0.0\n",
      "2                       tofu       4.0     9.0\n",
      "3       tofu shiratama dango       4.0     0.0\n",
      "14                     water       4.0     5.0\n",
      "20               white sugar       1.0     0.0\n",
      "PRECISION: 0.2807017543859649\n",
      "RECALL: 0.2077922077922078\n",
      "e443c33f56c338bc50653946ce88460b\n",
      "\n",
      "               term  expected  actual\n",
      "3   California roll       1.0     0.0\n",
      "0            Fro-Yo       3.0     0.0\n",
      "8            butter       1.0     2.0\n",
      "5            coffee       1.0     2.0\n",
      "17             diet       0.0     1.0\n",
      "15              egg       0.0     2.0\n",
      "11        egg salad       1.0     0.0\n",
      "12             eggs       6.0     5.0\n",
      "4     frozen yogurt       2.0     0.0\n",
      "7       goat's milk       3.0     0.0\n",
      "9              milk       1.0     4.0\n",
      "6           oatmeal       1.0     1.0\n",
      "16            salad       0.0     2.0\n",
      "13            sauce       0.0     1.0\n",
      "2         soy sauce       1.0     0.0\n",
      "1             sushi       5.0     5.0\n",
      "10              tea       1.0     1.0\n",
      "14           yogurt       0.0     2.0\n",
      "PRECISION: 0.5357142857142857\n",
      "RECALL: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "stories_dict = dict()\n",
    "#j_to_c exists to ensure that everything in the csv folder of our answers is in the storyjson on its own.\n",
    "#This also means that I haven't created tests yet for Instagram captions and the magazine covers.\n",
    "j_to_c = dict()\n",
    "contain = os.listdir(\"storyjsons\")\n",
    "for index in range(len(contain)):\n",
    "    j_to_c[contain[index][0:-5]] = index\n",
    "\n",
    "\n",
    "\n",
    "item_list = os.listdir(\"csvs\")\n",
    "#This will run the main system for each storyjson file, and create a comparison table each time.\n",
    "for element in item_list:\n",
    "    convert = element[0:-4]\n",
    "    if j_to_c.get(convert) is not None:\n",
    "        df = build_food_tester(convert)\n",
    "        stories_dict[convert] = df\n",
    "        #UNCOMMENT TO PRINT ALL RESULTS: print(df)\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ precall(df)      \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#Modify the array below with URLs you would like to look at, or leave it blank and uncomment above if you want all!:\n",
    "observe = [\"ff401e9686de3bec35052aa33a8382c5\", \"e443c33f56c338bc50653946ce88460b\"]\n",
    "for element in observe:\n",
    "    output = build_food_tester(element)\n",
    "    print(element + \"\\n\")\n",
    "    print(output)\n",
    "    precall(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce30c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
