{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e6a46a",
   "metadata": {},
   "source": [
    "# Model Tester (v1.1)\n",
    "Run the code below only once. It might take a few minutes, let it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24ad4960-0d8e-4c17-928f-b33237d331d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_lg')\r\n"
     ]
    }
   ],
   "source": [
    "# Import libraries:\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy wget -q\n",
    "!{sys.executable} -m spacy download en_core_web_lg -q\n",
    "!{sys.executable} -m pip install pandas\n",
    "import os\n",
    "import pickle\n",
    "import spacy\n",
    "from thinc.api import Config\n",
    "from spacy import Language\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_lg\n",
    "import wget\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "# Build the model. We only do this once per Binder instance.\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "url = \"https://mediacloud-ihop.s3.amazonaws.com/models/spacy_model.p\"\n",
    "take1 = wget.download(url)\n",
    "with open(\"spacy_model.p\", \"rb\") as h:\n",
    "\ttake = pickle.load(h)\n",
    "config = Config().from_disk(\"./config.cfg\")\n",
    "lang_cls = spacy.util.get_lang_class(config[\"nlp\"][\"lang\"])\n",
    "nlp = lang_cls.from_config(config)\n",
    "nlp = nlp.from_bytes(take)\n",
    "# The model should now be a file named \"spacy_model.p\" in the nav pane. This will NOT be in the Github.\n",
    "\n",
    "\n",
    "##Here are some functions for bigger testing.\n",
    "\n",
    "#This gives precision and recall numbers for a given dataframe created above.\n",
    "def precall(data):\n",
    "\tfalse_positives = 0\n",
    "\tfalse_negatives = 0\n",
    "\ttrue_positives = 0\n",
    "\tfor x in range(len(data)):\n",
    "\t\texpected = data.iloc[x,1]\n",
    "\t\tactual = data.iloc[x,2]\n",
    "\t\tif math.isnan(expected - actual): continue\n",
    "\t\telse:\n",
    "\t\t\tif expected == actual:\n",
    "\t\t\t\ttrue_positives += actual\n",
    "\t\t\telif expected > actual:\n",
    "\t\t\t\ttrue_positives += actual\n",
    "\t\t\t\tfalse_negatives += (expected - actual)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttrue_positives += expected\n",
    "\t\t\t\tfalse_positives += (actual - expected)\n",
    "\tprecision = true_positives / (true_positives + false_positives)\n",
    "\trecall = true_positives / (true_positives + false_negatives)\n",
    "\tprint(\"PRECISION: \" + str(precision))\n",
    "\tprint(\"RECALL: \" + str(recall))\n",
    "\n",
    "#This function takes the storyid for a storyjson blog post, and returns a dataframe with expected and actual results for each term in the post.\n",
    "def build_food_tester(convert):\n",
    "\n",
    "\t#First, do the json results.\n",
    "\tjsons_export = dict()\n",
    "\turl = \"https://mediacloud-ihop.s3.amazonaws.com/models/storyjsons/\" + convert + \".json\"\n",
    "\tfilepath = convert + \".json\"\n",
    "\tif (filepath) not in os.listdir():\n",
    "\t\tfilepath = wget.download(url)\n",
    "\twith open(filepath, 'rb') as json_file:\n",
    "\t\tfoo = json.load(json_file)\n",
    "\t\tbar = foo['content']\n",
    "\t\tdoc = nlp(bar) #Don't worry about any of these :)\n",
    "\n",
    "\t\tfor ents in doc.ents:\n",
    "\t\t\tif(ents.label_ != \"FOOD\"): continue\n",
    "\t\t\telif jsons_export.get(ents.text, -1) != -1:\n",
    "\t\t\t\tjsons_export[ents.text] += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tjsons_export[ents.text] = 1\n",
    "\t\n",
    "\t#Next, collect the data from the Manual Tests\n",
    "\tfilepath = \"./csvs/\" + convert + \".csv\"\n",
    "\tcsvs_export = pd.read_csv(filepath)\n",
    "\tcsvs_export = dict(zip(csvs_export.iloc[:,0], csvs_export.iloc[:,1]))\n",
    "\t#print(csvs_export)\n",
    "\n",
    "\t#Finally, put the lists together.\n",
    "\tdf = pd.DataFrame()\n",
    "\tdf = df.reindex(columns = [\"term\", \"expected\", \"actual\"])\n",
    "\tfor key in csvs_export:\n",
    "\t\tvalue3 = 0\n",
    "\t\tif jsons_export.get(key, -1) != -1:\n",
    "\t\t\tvalue3 = jsons_export[key]\n",
    "\t\t\tjsons_export[key] = -2\n",
    "\t\tdf.loc[len(df.index)] = [key, csvs_export[key], value3]\n",
    "\n",
    "\tfor key in jsons_export:\n",
    "\t\tif jsons_export[key] != -2:\n",
    "\t\t\tdf.loc[len(df.index)] = [key, 0, jsons_export[key]]\n",
    "\tdf = df.sort_values('term')\n",
    "\treturn df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a62b31",
   "metadata": {},
   "source": [
    "### User-Input Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962d611-3103-4ff7-8611-163f8a56127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a set of code for you to test everything out on your own; a personal sandbox!\n",
    "doc = nlp(\"bacon egg and cheese sandwich\")\n",
    "for token in doc:\n",
    "\tprint(token.text, token.pos_)\n",
    "for chunk in doc.noun_chunks:\n",
    "\tprint(chunk.text, chunk.root.text)\n",
    "for ents in doc.ents:\n",
    "\tprint(ents.text, ents.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adee444-e884-4c59-85b2-f9f7e07c478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer tags:\n",
      "[]\n",
      "Correct answer:\n",
      "[]\n",
      "Computer tags:\n",
      "['50%']\n",
      "Correct answer:\n",
      "[]\n",
      "Computer tags:\n",
      "['bacon', 'cheeseburger', 'onion', 'tomato', 'salsa', 'lemon', 'juice']\n",
      "Correct answer:\n",
      "['bacon', 'cheeseburger', 'lettuce', 'onion', 'tomato', 'salsa', 'lemon juice']\n",
      "Computer tags:\n",
      "['pepper', 'seasoning']\n",
      "Correct answer:\n",
      "['red pepper flakes', 'seasoning']\n",
      "Computer tags:\n",
      "['egg', 'eggs']\n",
      "Correct answer:\n",
      "['egg', 'egg', 'millefeuille']\n"
     ]
    }
   ],
   "source": [
    "# Testing random sentences.\n",
    "testsentences = ['', \n",
    "                 'get your car insurance at 50% average rates today by calling 334-808-1992', \n",
    "                 'today i ate a bacon cheeseburger with lettuce, onion and tomato. the salsa added to the top was too runny, so i would add some lemon juice on top.', \n",
    "                 'red pepper flakes are a great seasoning to add to many dishes.', \n",
    "                 'just one egg is fine, but i think two eggs will help the millefeuille maintain structure'\n",
    "                ]\n",
    "testanswers = [[], \n",
    "               [], \n",
    "               ['bacon', 'cheeseburger', 'lettuce', 'onion', 'tomato', 'salsa', 'lemon juice'], \n",
    "               ['red pepper flakes', 'seasoning'], \n",
    "               ['egg', 'egg', 'millefeuille']\n",
    "              ]\n",
    "counter = 0\n",
    "for sentence in testsentences:\n",
    "    doc = nlp(sentence)\n",
    "    nlp_answers = []\n",
    "    print(\"Computer tags:\")\n",
    "    for ents in doc.ents:\n",
    "        nlp_answers.append(ents.text)\n",
    "    print(nlp_answers)\n",
    "    print(\"Correct answer:\")\n",
    "    print(testanswers[counter])\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb02b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sushi': 5, 'sauce': 1, 'yogurt': 2, 'coffee': 2, 'oatmeal': 1, 'milk': 4, 'butter': 2, 'tea': 1, 'egg': 2, 'salad': 2, 'eggs': 5, 'diet': 1}\n"
     ]
    }
   ],
   "source": [
    "# Use this if you want to see the results from an entire storyjson file.\n",
    "def test_from_sjs(convert, print_text = False):\n",
    "    jsons_export = dict()\n",
    "    url = \"https://mediacloud-ihop.s3.amazonaws.com/models/storyjsons/\" + convert + \".json\"\n",
    "    filepath = convert + \".json\"\n",
    "    if filepath not in os.listdir(\"csvs\"):\n",
    "        filepath = wget.download(url)\n",
    "    with open(filepath, 'rb') as json_file:\n",
    "        foo = json.load(json_file)\n",
    "        bar = foo['content']\n",
    "        if print_text: print(bar)\n",
    "        doc = nlp(bar)\n",
    "\n",
    "        for ents in doc.ents:\n",
    "            if(ents.label_ != \"FOOD\"): continue\n",
    "            elif jsons_export.get(ents.text, -1) != -1:\n",
    "                jsons_export[ents.text] += 1\n",
    "            else:\n",
    "                jsons_export[ents.text] = 1\n",
    "    return jsons_export\n",
    "\n",
    "print(test_from_sjs(\"e443c33f56c338bc50653946ce88460b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cd571",
   "metadata": {},
   "source": [
    "### Manual Tests (from manually-entered csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1486bc86-c0a3-4d7a-a609-07c10501407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instagram.com_p_CbYHj4cB_S2_.csv\n",
      "ff401e9686de3bec35052aa33a8382c5.csv\n",
      "a5d7a468b900da50f787f11e10673224.csv\n",
      "instagram.com_p_BmwXCK2nAK8_.csv\n",
      "c332838cb3ab544ce16aaaf0d30d1587.csv\n",
      "instagram.com_p_CY4XZ16Bvyf_.csv\n",
      "7a2421f687bf90732cf4ba727ab6b09b.csv\n",
      "613aa03ee246323cd6ffcc4ea03e68cc.csv\n",
      ".DS_Store\n",
      "a85cbd99b2dba1cd1dbc31b46952ac76.csv\n",
      "703a2a8217ed493e0ae29b81386aa9b4.csv\n",
      "instagram.com_p_CautFXhhpil_.csv\n",
      "instagram.com_p_CAsvIekHOVG_.csv\n",
      "ca6f92e3a1f112f6714cfa69bbe90cd0.csv\n",
      "BA June-July 2019.csv\n",
      "BA Dec 2019 - Jan 2020 .csv\n",
      "instagram.com_p_CbgKjuGh4Ir_.csv\n",
      "0acff7d82116e5c0f1b3eb1b6b5bade8.csv\n",
      "instagram.com_p_Bnt5-sRndK7_.csv\n",
      "BA June-July 2018.csv\n",
      "BA June-July 2020.csv\n",
      "instagram.com_p_BnR5DxyHioP_.csv\n",
      "BA Dec 2021 - Jan 2022 .csv\n",
      "BA June-July 2021.csv\n",
      "c3f04ed913c48f33238d9764c3817cfb.csv\n",
      "0cf67eb7f52cd235509b530bf7c3ea9b.csv\n",
      "instagram.com_p_CbSUwTSMqwC_.csv\n",
      "f3d1c80cb0263594aadf4903d4ff448b.csv\n",
      "fa262c03a3f536e5165fc0e9cd061b64.csv\n",
      "BA March 2019.csv\n",
      "instagram.com_p_CbQSUT9Bnu0_.csv\n",
      "cc834cc2d8291bcc4811387dfc810c94.csv\n",
      "BA March 2020.csv\n",
      "BA March 2021.csv\n",
      "b0d7baca212c60b884de5ccdb5025b28.csv\n",
      "c3aeef89e389f90bb137f28204861b49.csv\n",
      "instagram.com_p_Cau60Jyh2sJ_.csv\n",
      "instagram.com_p_CbnkT1HhZNq_.csv\n",
      "e443c33f56c338bc50653946ce88460b.csv\n",
      "a5b2c77925de0529df3fcfce06c75243.csv\n",
      "BA Dec 2018 - Jan 2019 .csv\n",
      "instagram.com_p_B9j0eaIH13P_.csv\n",
      "0b12807f55062696086ad3831211c284.csv\n",
      "239d90cb32a74d64daf8952cafca791d.csv\n",
      "BA Sept 2020.csv\n",
      "BA Sept 2021.csv\n",
      "BA Sept 2019.csv\n",
      "BA Sept 2018.csv\n",
      "5316376137984291a684487b1ff7b68f.csv\n",
      "7e3345fe9fad3a161ac8aa11fa214831.csv\n",
      "3db89c985c314dbdc4bc6244e2bd4e01.csv\n",
      "a94ef4308e8cae75766fea73531918c1.csv\n",
      "f83238aabbb6f29fc5f33b48bbf3efde.csv\n",
      "BA Dec 2020 - Jan 2021 .csv\n",
      "ff401e9686de3bec35052aa33a8382c5\n",
      "\n",
      "                        term  expected  actual\n",
      "27                     azuki       1.0     0.0\n",
      "37                     broth       1.0     1.0\n",
      "51                      cake       0.0     1.0\n",
      "29         candied chestnuts       1.0     0.0\n",
      "40                      chew       0.0     2.0\n",
      "42                     chewy       0.0     2.0\n",
      "28              chiffon cake       1.0     0.0\n",
      "56                     chips       0.0     1.0\n",
      "55                 chocolate       0.0     2.0\n",
      "38  chocolate chip ice cream       1.0     0.0\n",
      "39           chocolate chips       1.0     0.0\n",
      "45                confection       0.0     1.0\n",
      "26                cornflakes       1.0     0.0\n",
      "44                     cream       0.0     3.0\n",
      "4                      dango       9.0     0.0\n",
      "34                     dashi       1.0     0.0\n",
      "52                   dessert       0.0     2.0\n",
      "0                  dumplings       3.0     2.0\n",
      "36                       egg       1.0     1.0\n",
      "7                      flour       NaN     4.0\n",
      "47                     glaze       0.0     4.0\n",
      "43                       ice       0.0     4.0\n",
      "8                  ice cream       3.0     0.0\n",
      "15                     maple       1.0     0.0\n",
      "30               maple glaze       1.0     0.0\n",
      "18               maple syrup       3.0     0.0\n",
      "53                      miso       0.0     1.0\n",
      "17           mitarashi dango       2.0     0.0\n",
      "1                      mochi       6.0     0.0\n",
      "13                   mochiko       1.0     0.0\n",
      "33                     onion       1.0     1.0\n",
      "31                     ozoni       3.0     0.0\n",
      "24                  parfaits       2.0     0.0\n",
      "50                    peanut       0.0     1.0\n",
      "23             peanut powder       1.0     0.0\n",
      "54                     poach       0.0     1.0\n",
      "21             potato starch       1.0     0.0\n",
      "35                  red miso       1.0     0.0\n",
      "41                      rice       0.0     5.0\n",
      "5                 rice flour       3.0     0.0\n",
      "6             rice mochigome       NaN     0.0\n",
      "48                     sauce       0.0     2.0\n",
      "11               shiratamako       2.0     0.0\n",
      "12               silken tofu       1.0     0.0\n",
      "46                    smooth       0.0     1.0\n",
      "25                soft-serve       1.0     0.0\n",
      "10                      soup       4.0     3.0\n",
      "16                       soy       2.0     0.0\n",
      "19                 soy sauce       2.0     0.0\n",
      "32               sticky rice       1.0     0.0\n",
      "49                     sugar       0.0     2.0\n",
      "9                      syrup       NaN     5.0\n",
      "22     toasted soybean powde       1.0     0.0\n",
      "2                       tofu       4.0     9.0\n",
      "3       tofu shiratama dango       4.0     0.0\n",
      "14                     water       4.0     5.0\n",
      "20               white sugar       1.0     0.0\n",
      "PRECISION: 0.2807017543859649\n",
      "RECALL: 0.2077922077922078\n",
      "e443c33f56c338bc50653946ce88460b\n",
      "\n",
      "               term  expected  actual\n",
      "3   California roll       1.0     0.0\n",
      "0            Fro-Yo       3.0     0.0\n",
      "8            butter       1.0     2.0\n",
      "5            coffee       1.0     2.0\n",
      "17             diet       0.0     1.0\n",
      "15              egg       0.0     2.0\n",
      "11        egg salad       1.0     0.0\n",
      "12             eggs       6.0     5.0\n",
      "4     frozen yogurt       2.0     0.0\n",
      "7       goat's milk       3.0     0.0\n",
      "9              milk       1.0     4.0\n",
      "6           oatmeal       1.0     1.0\n",
      "16            salad       0.0     2.0\n",
      "13            sauce       0.0     1.0\n",
      "2         soy sauce       1.0     0.0\n",
      "1             sushi       5.0     5.0\n",
      "10              tea       1.0     1.0\n",
      "14           yogurt       0.0     2.0\n",
      "PRECISION: 0.5357142857142857\n",
      "RECALL: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "stories_dict = dict()\n",
    "\n",
    "#This will run the main system for each storyjson file, and create a comparison table each time. This might take a while.\n",
    "for element in os.listdir(\"csvs\"):\n",
    "    convert = element[0:-4]\n",
    "    if element[0:2] != \"BA\" and element[0:9] != \"instagram\" and element != \".DS_Store\": #Weird # of exceptions...\n",
    "        df = build_food_tester(convert)\n",
    "        stories_dict[convert] = df\n",
    "        #UNCOMMENT TO PRINT ALL RESULTS: print(df)\n",
    "        #^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ precall(df)      \n",
    "        \n",
    "#Modify the array below with URLs you would like to look at, or leave it blank and uncomment above if you want all!:\n",
    "observe = [\"ff401e9686de3bec35052aa33a8382c5\", \"e443c33f56c338bc50653946ce88460b\"]\n",
    "for element in observe:\n",
    "    output = build_food_tester(element)\n",
    "    print(element + \"\\n\")\n",
    "    print(output)\n",
    "    precall(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e38eea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         term  expected  actual\n",
      "8           all-purpose flour       2.0     0.0\n",
      "4                      butter       1.0     2.0\n",
      "34                      chard       1.0     0.0\n",
      "43                      chill       0.0     1.0\n",
      "16  crushed red pepper flakes       1.0     0.0\n",
      "44                     delish       0.0     1.0\n",
      "54        delish!AnonymousSan       0.0     1.0\n",
      "24                       dill       1.0     0.0\n",
      "46                        dip       0.0     1.0\n",
      "7                       dough       7.0     0.0\n",
      "21                        egg       1.0     3.0\n",
      "12     extra-virgin olive oil       2.0     0.0\n",
      "49                       feta       0.0     1.0\n",
      "28                      flour       1.0     2.0\n",
      "36                    floured       1.0     0.0\n",
      "1                     galette       3.0     6.0\n",
      "32                     garlic       2.0     3.0\n",
      "15              garlic cloves       1.0     0.0\n",
      "20                     grated       1.0     0.0\n",
      "22               greek yogurt       1.0     0.0\n",
      "3                       green       1.0     0.0\n",
      "18              ground pepper       1.0     0.0\n",
      "23                      herbs       2.0     0.0\n",
      "41                        ice       0.0     1.0\n",
      "31                  ice water       1.0     0.0\n",
      "52                       kale       0.0     2.0\n",
      "10                kosher salt       1.0     0.0\n",
      "13                       leek       2.0     0.0\n",
      "48                      leeks       0.0     1.0\n",
      "39                      lemon       0.0     3.0\n",
      "27                 lemon zest       2.0     0.0\n",
      "47                       nuts       0.0     1.0\n",
      "30                        oil       2.0     4.0\n",
      "0                   olive oil       1.0     0.0\n",
      "50                      onion       0.0     1.0\n",
      "19                   parmesan       2.0     0.0\n",
      "25                    parsley       1.0     2.0\n",
      "35                     pepper       1.0     7.0\n",
      "37                        pie       0.0     1.0\n",
      "5                   pie dough       1.0     0.0\n",
      "38                      plain       0.0     1.0\n",
      "11               plain yogurt       1.0     0.0\n",
      "45                    pretzel       0.0     1.0\n",
      "33          red pepper flakes       1.0     0.0\n",
      "29                       salt       1.0     2.0\n",
      "14                  scallions       1.0     0.0\n",
      "51                   shallots       0.0     1.0\n",
      "40                     smooth       0.0     1.0\n",
      "2                       spicy       1.0     0.0\n",
      "53                    spinach       0.0     1.0\n",
      "9                       sugar       2.0     1.0\n",
      "17                swiss chard       3.0     0.0\n",
      "26                   tarragon       1.0     2.0\n",
      "42                      water       0.0     1.0\n",
      "6                      yogurt       4.0    12.0\n"
     ]
    }
   ],
   "source": [
    "#Of course, if you'd like, you can run this function against any manually checked ID:\n",
    "print(build_food_tester(\"a94ef4308e8cae75766fea73531918c1\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
